---
title: "Preprocessing_16S_subset"
author: "Yupawadee Galasong"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Load packages
```{r}
pacman::p_load(dada2, tidyverse, phyloseq, patchwork,Biostrings, install = FALSE)
```
# Install an additional package for cutadapt

```{r}
pacman::p_load(devtools, DelayedArray, GenomeInfoDb, ShortRead, install = FALSE)
install_github("omicsCore/SEQprocess")
library("SEQprocess") # Loads the package
#library(help="SEQprocess") # Lists package info
```

# Set up file path
```{r}
path <- "./Data_16S"
```

# Renaming files
This part will be skipped for now. We only want to see the overall read quality,
sequencing output, and whether the Nakano primers yield lower mitochondria & chloroplast reads
compared to the universal 16S primers.

# Create variables for the forward and reverse reads
```{r}
#Forward read variables
forward_reads <- list.files(path, pattern = "R1", full.names = TRUE)

#Reverse read variables 
reverse_reads <- list.files(path, pattern = "R2", full.names = TRUE)
```

# Create a list of sample names
In Terminal, use ls command to list the file names and pipe the output to a new
txt file called "samples_16S_subset.txt".
```{r list sample names}
#Remove _R[1,2].fastq.gz extension to obtain true sample names
samples <- list()
filenames <- scan("samples_16S_subset.txt",character())
for(name in filenames){
  sample <- gsub("_R[0-9].fastq.gz",'',name)
  if(!sample %in% samples){
  samples <- append(samples,sample)
  }
}
#IMPORTANT: sort the 'samples' vector alphabetically so it matches with how R list the files in the path
samples <- sort(unlist(samples))
```

#Create varibales for filtered forward and reverse reads
```{r}
filtered_forward_reads <- file.path(path, "filtered", paste0(samples,"_R1_filtered.fastq.gz"))

filtered_reverse_reads <- file.path(path, "filtered", paste0(samples,"_R2_filtered.fastq.gz"))
```


#Assess Raw Read Quality
The raw read quality for samples #2 and #9 is poor. These are pasteurized orange juice and pasteurized cider, respectively.
```{r Assess Raw Read Quality}
#Display quality plot for forward read samples
forwardQualPlot <- plotQualityProfile(forward_reads)
forwardQualPlot
#Display quality plot for  reverse read samples
reverseQualPlot <- plotQualityProfile(reverse_reads)
reverseQualPlot
```

#primers and adapters from raw reads
```{r primers info}
fwd_primer <- "CADACTCCTACGGGAGGC"
rev_primer <- "ATCCTGTTTGMTMCCCVCRC"
rev_rc <- toString(reverseComplement(DNAString(rev_primer)))
fwd_rc <- toString(reverseComplement(DNAString(fwd_primer)))

```
#Some additional steps before primer removal
Following this tutorial: https://benjjneb.github.io/dada2/ITS_workflow.html

```{r primer orientation}
allOrients <- function(primer) {
    # Create all orientations of the input sequence
    require(Biostrings)
    dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
    orients <- c(Forward = dna, Complement = complement(dna), Reverse = reverse(dna), 
        RevComp = reverseComplement(dna))
    return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(fwd_primer)
REV.orients <- allOrients(rev_primer)
FWD.orients
```

#Pre-filtering N's from raw reads & Count primers
```{r filter Ns from raw seqs}
forward_reads.filtN <- file.path(path, "filtN", basename(forward_reads)) # Put N-filterd files in filtN/ subdirectory
reverse_reads.filtN <- file.path(path, "filtN", basename(reverse_reads))
filterAndTrim(forward_reads, forward_reads.filtN, reverse_reads, reverse_reads.filtN, maxN = 0, multithread = TRUE)
primerHits <- function(primer, fn) {
    # Counts number of reads in which the primer is found
    nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
    return(sum(nhits > 0))
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = forward_reads.filtN[[1]]), 
    FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = reverse_reads.filtN[[1]]), 
    REV.ForwardReads = sapply(REV.orients, primerHits, fn = forward_reads.filtN[[1]]), 
    REV.ReverseReads = sapply(REV.orients, primerHits, fn = reverse_reads.filtN[[1]]))
```

#Cutadapt
```{r cutadapt}
cutadapt <- "/home/yg225/cutadapt-venv/bin/cutadapt"
path.cut <- file.path(path, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
forward_reads.cut <- file.path(path.cut, basename(forward_reads))
reverse_reads.cut <- file.path(path.cut, basename(reverse_reads))
R1.flags <- paste("-g", fwd_primer, "-a", rev_rc)
R2.flags <- paste("-G", rev_primer, "-A", fwd_rc)
# Run Cutadapt
for(i in seq_along(forward_reads)) {
  system2(cutadapt,args = c(R1.flags, R2.flags, "-n", 2, "-m", 1,
  # -n 2 required to remove FWD and REV from reads
  # -m 1 required to prevent error in PlotQualityProfile post cutadapt
  "-o", forward_reads.cut[i], "-p", reverse_reads.cut[i], # output files
  forward_reads.filtN[i], reverse_reads.filtN[i], "--discard-untrimmed",
  "--report=minimal"))
}

```

```{r post-cutadapt check}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = forward_reads.cut[[1]]), 
    FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = reverse_reads.cut[[1]]), 
    REV.ForwardReads = sapply(REV.orients, primerHits, fn = forward_reads.cut[[1]]), 
    REV.ReverseReads = sapply(REV.orients, primerHits, fn = reverse_reads.cut[[1]]))

```

```{r Assess Raw Read Quality}
#Display quality plot for forward read samples
forwardQualPlot_cut <- plotQualityProfile(forward_reads.cut)
#Display quality plot for  reverse read samples
reverseQualPlot_cut <- plotQualityProfile(reverse_reads.cut)
```
The primer-free sequence files are now ready to be analyzed through the DADA2 pipeline!

#Filter and Trim Reads
```{r Filter and Trim}
filtered_out <- filterAndTrim(forward_reads.cut, filtered_forward_reads,
                              reverse_reads.cut, filtered_reverse_reads,
                              #truncLen = c(232,230),
                              maxN = 0, maxEE = c(2,2),
                              truncQ = 2,
                              rm.phix = TRUE,
                              compress = TRUE,
                              multithread = TRUE)
filtered_out
#Plot the quality plot of trimmed reads
forwardQualPlot_filt <- plotQualityProfile(filtered_forward_reads)
reverseQualPlot_filt <- plotQualityProfile(filtered_reverse_reads)

#Optional: Putting all quality plots into 1 gigantic plot
(forwardQualPlot + reverseQualPlot) / (forwardQualPlot_filt + reverseQualPlot_filt)

```

#Generate an Error Model
```{r learn-errors}
#Learn errors
err_forward_reads <- learnErrors(filtered_forward_reads, multithread = TRUE)
err_reverse_reads <- learnErrors(filtered_reverse_reads, multithread = TRUE)

#Plot the errors
error_model_fwd <- plotErrors(err_forward_reads, nominalQ = TRUE)
error_model_rev <- plotErrors(err_reverse_reads, nominalQ = TRUE)
```

# Inferring ASVs on the forward and reverse sequences
```{r denoising}
# Run DADA2 on forward sequences
dada_forward <- dada(filtered_forward_reads, err = err_forward_reads, multithread = TRUE)
head(dada_forward)

# Run DADA2 on reverse sequences
dada_reverse <- dada(filtered_reverse_reads, err = err_reverse_reads, multithread = TRUE)
head(dada_reverse)

```
# Merge the forward and reverse ASVs
```{r Merge}
# Merge forward ASVs and reverse ASVs
merged_amplicons <- mergePairs(dadaF = dada_forward, 
                               derepF = filtered_forward_reads, 
                               dadaR = dada_reverse, 
                               derepR = filtered_reverse_reads,
                               verbose = TRUE)
#Inspect the output
head(merged_amplicons)
```
#Generate a count table
```{r seqtab}
seqtab <- makeSequenceTable(merged_amplicons)
class(seqtab)
typeof(seqtab)
dim(seqtab)

#Inspect the distribution of sequence lengths of all ASVs in the data set
table(nchar(getSequences(seqtab)))

```

# Search & Remove Chimeras (or Bimeras)
```{r Chimeras}
seqtab_nochim <- removeBimeraDenovo(seqtab, verbose = TRUE, multithread = TRUE)

# Calculate percentage of chimeras removed

frac_removed <- (1-sum(seqtab_nochim)/sum(seqtab))*100
paste0("Chimeras represented ", frac_removed, "% of merged reads")

```

Chimeras represented `r frac_removed` % of the data
```{r track table}
# Create a function to identify the number of sequences
getN <- function(x) sum(getUniques(x))

# Make the table to track the sequences
track <- cbind(filtered_out,
               sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_amplicons, getN),
               rowSums(seqtab_nochim))
head(track)

#Change the column names
colnames(track) <- c("input","filtered","denoisedF","denoisedR","merged","nochim")

#Change the row names to samples names
rownames(track) <-  samples
```

```{r tracking reads through pipeline}

#Generate a plot to track the reads through our DADA2 pipeline

#Tip: to track the progress of the pipeline (or just for sanity check), add %>% head() to see how the data frame changes after each command

track_pct <- track %>% as.data.frame() %>% rownames_to_column(var = "names") %>% rowwise() %>% mutate(filtered = filtered/input, denoisedF = denoisedF/input, denoisedR = denoisedR/input, merged = merged/input, nochim = nochim/input)

track %>% as.data.frame() %>% rownames_to_column(var = "names") %>% pivot_longer(input:nochim, names_to = "read_type", values_to = "num_reads") %>%
  mutate(read_type = fct_relevel(read_type, "input", "filtered", "denoisedF", "denoisedR","merged","nochim")) %>%
  ggplot(aes(x = read_type,y = num_reads, fill = read_type)) + 
  geom_line(aes(group = names), color = "grey") +
  geom_point(shape = 21, size = 3, alpha = 0.8) +
  scale_fill_brewer(palette = "Spectral") +
  theme_bw()+
  labs(x = "Filtering Step", y = "Number of Sequences")+
  theme(legend.position = "bottom", legend.title = element_blank(),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
  
```
# Assign Taxonomy 

Here, we will use the silva database version 138!
```{r assign-tax}
SILVA_train_path <- "/workdir/yg225/JuiceMicrobiome/SILVA/silva_nr99_v138.1_train_set.fa.gz"

SILVA_species_path <- "/workdir/yg225/JuiceMicrobiome/SILVA/silva_species_assignment_v138.1.fa.gz"

taxa <- assignTaxonomy(seqtab_nochim, SILVA_train_path, multithread=TRUE)

taxa <- addSpecies(taxa, SILVA_species_path)

# Inspect the taxonomy 
taxa_print <- taxa 
# Removing sequence row names for display only
rownames(taxa_print) <- NULL
View(taxa_print)
```
# Prepare data for export!
## 1. ASV Table
```{r}
# Prep the ASV table
samples_out <- rownames(seqtab_nochim)

# Extract sample names from the FASTQ file name
sample_names_reformatted <- gsub("_10471140_L9NR7_R1_filtered.fastq.gz","",samples_out)

# Replace the names in our seqtab
rownames(seqtab_nochim) <- sample_names_reformatted

#Intuition check
stopifnot(rownames(seqtab_nochim) == sample_names_reformatted)

## Modify the ASV names and then save as a fasta file ##
# First we give headers more manageable name
asv_seqs <- colnames(seqtab_nochim)

# Make headers for our ASV seq fasta file, which will be our asv names 
asv_headers <- vector(dim(seqtab_nochim)[2], mode = "character")
for(i in seq(dim(seqtab_nochim)[2])){
  asv_headers[i] <- paste(">ASV",i,sep = "_")
}
asv_tab <- t(seqtab_nochim)
row.names(asv_tab) <- sub(">","", asv_headers)
write.table(asv_tab, "Data_16S/ASV_counts.tsv", sep = "\t", quote = FALSE, col.names = NA)

# Write out the fasta file for reference later on for what seq matchs what ASV
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "Data_16S/ASVs.fasta")
```

## 2. Taxonomy table
```{r prepare taxonomy table}
## Prepare tax-table
# Add the ASV sequences from the row names to a column
new_tax_tab <- taxa %>% as.data.frame() %>% rownames_to_column(var = "ASVseqs")
head(new_tax_tab)

#Intuition check
stopifnot(new_tax_tab$ASVseqs == colnames(seqtab_nochim))

# Add ASV names
rownames(new_tax_tab) <- rownames(asv_tab)

# Add new column with ASV names
asv_tax <-new_tax_tab %>% mutate(ASV = rownames(asv_tab)) %>% 
  dplyr::select(Kingdom, Phylum, Class, Order, Family, Genus, Species, ASV, ASVseqs)

#View(asv_tax)

stopifnot(asv_tax$ASV == rownames(asv_tax), rownames(asv_tax) == rownames(asv_tab))

write.table(asv_tax, "Data_16S/ASV_taxonomy.tsv", sep = "\t", quote = FALSE, col.names = NA)

```
## 3. Metadata
```{r metadata}
library(readr)
metadata <- read_csv("data/16S_metadata.csv", col_types = cols(Date = col_skip(), V1 = col_skip()))
colnames(metadata)[1] <- "names"
metadata$TrueSampleOrControl <- ifelse(metadata$Replicate == "NC","Control","True Sample")

harvest_data <- read_csv("data/harvest_data.csv")

finished_product_data <- read_csv("data/finished_product_data.csv")

full_metadata <- metadata %>% left_join(y = harvest_data,by = "SampleLot") %>% left_join(y = finished_product_data, by = "SampleLot")

#Remove samples that are present in the metadata but were not sequenced
full_metadata <- full_metadata[-c(10:12),]
full_metadata <- full_metadata[-c(14:15,50),]

#rearrage rows to match ASV table columns
full_metadata <- full_metadata[match(colnames(asv_tab), full_metadata$names), ]
stopifnot(sort(full_metadata$names) == sort(sample_names_reformatted))
rownames(full_metadata) <- full_metadata$names
```

```{r phyloseq-handoff}
full_metadata <- sample_data(full_metadata)
row.names(full_metadata) <- full_metadata$names

raw_physeq <- phyloseq(otu_table(asv_tab, taxa_are_rows = TRUE),
                       sample_data(full_metadata), tax_table(as.matrix(asv_tax)))
raw_physeq
save(raw_physeq, file = paste0("data/raw_physeq.RData"))
```